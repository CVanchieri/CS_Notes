{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_FeedForward(MLP)_NeuralNetwork.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFM5sl2ef0Cg"
      },
      "source": [
        "## Feed Forward (MLP) Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHYXNoDvORIF"
      },
      "source": [
        "### Neural Networks\n",
        "#### Neural networks are a series of algorithms that identify underlying relationships in a set of data. These algorithms are heavily based on the way a human brain operates. These networks can adapt to changing input and generate the best result without the requirement to redesign the output criteria.  Deep learning algorithms are based on neural networks.\n",
        "\n",
        "#### Neural Networks Components:\n",
        "\n",
        "- an input layer that receives data and pass it on\n",
        "- a hidden layer\n",
        "- an output layer\n",
        "- weights between the layers\n",
        "- a deliberate activation function for every hidden layer\n",
        "\n",
        "#### Pros \n",
        "- flexible and can be used for both regression and classification problems\n",
        "- good to model with nonlinear data with large number of inputs; for example, images\n",
        "- reliable in an approach of tasks involving many features\n",
        "- predictions are fast once trained\n",
        "\n",
        "#### Cons\n",
        "- only numerical data \n",
        "- needs alot of data to work well \n",
        "- very complex, we cannot know how much each independent variable is influencing the dependent variables\n",
        "- computationally very expensive and time consuming to train with traditional CPUs\n",
        "- very dependant on training data, leads to the problem of over-fitting and generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhRHMqRaQfiG"
      },
      "source": [
        "### Model Set Up\n",
        "\n",
        "#### Steps\n",
        " - load the data\n",
        " - inspect, clean, organize data\n",
        " - check for, handle outliers \n",
        " - encode data if necessary \n",
        " - set features and target \n",
        " - train, test split the data \n",
        " - scale the data if necessary \n",
        " - build, compile the model, fit the data, evaluate the model \n",
        " - run metrics, analyze, view results, adjust parameters, repeat until satisfied... \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hmqr8qAMLuE"
      },
      "source": [
        "### Neural Network Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9Z_XK3rO7H6"
      },
      "source": [
        "#### Multilayer Perceptrons (MLP), feed forward\n",
        "\n",
        "![photo](https://static.packt-cdn.com/products/9781788397872/graphics/1ebc2a0a-2123-4351-b7e1-eb57f098bafa.png)\n",
        " - feedforward, often need back-propagation, which provides the network with corresponding set of inputs and outputs. When the input data is transmitted into the neuron, it is processed, and an output is generated.\n",
        " - 3 layers, nodes/input layer, hidden layer, output layer\n",
        " - in hidden and the output layers, every node is considered as a neuron with a nonlinear activation function\n",
        " - supervised learning technique called backpropagation for training, adjusts weights of neurons\n",
        " - most ideal for projects involving tabular datasets, classification prediction problems, and regression prediction problems\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUXplGBBRmeD"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCbiZ7J-V55T"
      },
      "source": [
        "#### Import + Inspect "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThIRPgzSjP1T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95676981-62c5-4f74-9f68-4c57a751b71b"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist # load the fashion-MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data() # split data for X train, y train"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YltWjPbwcDlT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c563d4c4-d0db-447a-cd88-e1eadff208f6"
      },
      "source": [
        "X_train[25] # show the array for 25"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  83,\n",
              "         91, 143, 255, 190,  91,  50,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   9,  49, 180, 246,\n",
              "        253, 253, 253, 253, 253, 220, 154,  17,   3,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  46, 107, 178, 253, 253, 253,\n",
              "        253, 253, 253, 253, 253, 253, 253, 253, 126,  45,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 107, 253, 253, 253, 253, 223,\n",
              "        220, 220, 220, 220, 245, 253, 253, 253, 253, 106,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 107, 173, 253, 229, 129,  12,\n",
              "          0,   0,   0,   0, 110, 253, 253, 253, 253, 106,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  17,  14,  40,  32,   0,   0,\n",
              "          0,   0,   0,   0,  57, 253, 253, 253, 242,  85,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   5, 139, 224, 253, 253, 253, 105,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  65, 178, 253, 253, 253, 253, 219,  24,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         97, 250, 253, 253, 253, 253, 127,  47,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 125,\n",
              "        250, 253, 253, 253, 245, 171,  33,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   5,  41, 217, 253,\n",
              "        253, 250, 245, 245, 115,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 124, 253, 253, 253,\n",
              "        192, 105,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  11,  47, 220, 253, 253, 188,\n",
              "         25,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 107, 253, 253, 253, 189,  13,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  41, 225, 253, 253, 186,  22,   0,\n",
              "          0,   0,   0,   0,  31,  42, 174, 205, 205, 205, 193,  58,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,  48, 218, 253, 253, 253, 150,  59,   0,\n",
              "          0, 128, 131, 131, 222, 253, 253, 253, 253, 253,  94,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,  12, 152, 253, 253, 253, 253, 236, 222,\n",
              "        222, 252, 253, 253, 253, 253, 253, 253, 253, 253, 122,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   7, 167, 253, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 253, 253, 253, 253, 124, 106,   7,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  76, 188, 253, 253, 253, 253,\n",
              "        253, 253, 253, 224,  57,  15,  15,  15,   2,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  12,  89, 121, 253, 253,\n",
              "        151,  89,  89,  55,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "xsEHE1mhb9JN",
        "outputId": "d8f6848c-7a82-4675-ed2e-70089edc0719"
      },
      "source": [
        "### show what image the array makes ###\n",
        "import matplotlib.pyplot as plt \n",
        "plt.imshow(X_train[25], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6f36fd8128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7AXVEyNPKBj"
      },
      "source": [
        "#### Reshape + Encode "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z4k1D0uekFE"
      },
      "source": [
        "### reshape the data ### \n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_GOvh2rVjBm"
      },
      "source": [
        "### set X variable types to float ### \n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "### set classes, convert vectors to binary class matrix ###\n",
        "num_classes = 10\n",
        "from tensorflow import keras \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEQzqEqfO4ha"
      },
      "source": [
        "#### (MLP) Feed Forward Neural Network\n",
        " - GridSearch CV \n",
        " - RandomizedSearch CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CYBuj9ymGuS",
        "outputId": "d58c6f48-8670-4af9-8343-dbee0b62411a"
      },
      "source": [
        "from tensorflow import keras \n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.activations import relu, sigmoid\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "seed = 7\n",
        "np.random.seed(seed) # random seed for reproducability\n",
        "### create the model ###\n",
        "model = Sequential() # initiate the model \n",
        "model.add(Dense(50, input_dim=784, activation='relu')), # input layer, set dimension\n",
        "model.add(Dropout(0.1)), # set a drop out \n",
        "model.add(Dense(100, activation='relu')), # hidden layer\n",
        "model.add(Dropout(0.1)), # set a drop out \n",
        "model.add(Dense(50, activation='relu')), # hidden layer\n",
        "model.add(Dense(10, activation='sigmoid')) # output layer \n",
        "model.compile( # compile the model \n",
        "              optimizer = 'adam', \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy']\n",
        "              )\n",
        "### show summary ### \n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 50)                39250     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               5100      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 49,910\n",
            "Trainable params: 49,910\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kkpHnIlm_VO",
        "outputId": "2d0addf1-f944-43e7-fbed-9bc808da9c35"
      },
      "source": [
        "print('--- model runtime ---')\n",
        "%time history = model.fit(X_train, y_train, batch_size=20, epochs=50, validation_split=.1, verbose=False) # fit the model \n",
        "scores = model.evaluate(X_test, y_test) # get the model score from evaluation\n",
        "print(f'model accuracy = {scores[1]*100}') # show the models accuracy score "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- model runtime ---\n",
            "CPU times: user 4min 35s, sys: 24.7 s, total: 5min\n",
            "Wall time: 3min 15s\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2327 - accuracy: 0.9551\n",
            "model accuracy = 95.50999999046326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifq1RQ0JmNwh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "56ef134b-e746-4dfb-a9dc-b90d450e4627"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "### plot the model loss ###\n",
        "### configure the plot ###\n",
        "print('--- model loss-MAE --- ')\n",
        "f, ax = plt.subplots(1, 1, figsize = (10, 7))\n",
        "ax1 = plt.plot(history.history['loss'], color=\"r\", label=\"loss-MSE\")\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- model loss-MAE --- \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8oOsLF4havx"
      },
      "source": [
        "##### GridSearch CV "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "YvOglyabxDUO",
        "outputId": "a7181ce2-df5b-4980-e4bb-c5e41e294424"
      },
      "source": [
        "### parameter tuning options ###\n",
        "'''\n",
        "- tune 1-2 parameters at a time \n",
        "- add parameters to model function input\n",
        "- set the list of values for the parameter in the model \n",
        "- add the parameter to the param_grid dictionary\n",
        "'''\n",
        "# def create_model(optimizer='rmsprop', init='glorot_uniform',dropout_rate=0.0, weight_constraint=0, activation='relu', learn_rate=0.01, momentum=0, neurons=1)\n",
        "# optimizers = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "# init = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'] # network weight initializer, will change with choice of activation function \n",
        "# activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'], # controls the non-linearity of individual neurons and when to fire, 'sigmoid' last layer for 0-1 value outputs\n",
        "# epochs = [10, 50, 100] # no model input necessary, how many times the model will run \n",
        "# batch_size = [5, 10, 20] # no model input necessary, # of samples to run in each epoch\n",
        "# learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3] # combine with momentum, use SGD optimizer, how much to update the weight after each batch  \n",
        "# momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9] # combine with learn_rate, use SGD optimizer\n",
        "# optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
        "# weight_constraint = [1, 2, 3, 4, 5] # combine with dropout \n",
        "# dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] # combine with weight_constraint\n",
        "# neurons = [1, 5, 10, 15, 20, 25, 30]\n",
        "# param_grid = dict(batch_size=batch_size, epochs=epochs, batch_size=batch_size, learn_rate=learn_rate, momentum=momentum, weight_constraint=weight_constraint, dropout_rate=dropout_rate, neurons)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n- tune 1-2 parameters at a time \\n- add parameters to model function input\\n- set the list of values for the parameter in the model \\n- add the parameter to the param_grid dictionary\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALt54gcLe_P1",
        "outputId": "b5983b80-03f9-4d21-fb85-a30487cb618a"
      },
      "source": [
        "from tensorflow import keras \n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.activations import relu, sigmoid\n",
        "from sklearn.model_selection import cross_val_score\n",
        "### create model function ###\n",
        "def create_model():\n",
        "    model = Sequential() # initiate the model \n",
        "    model.add(Dense(50, input_dim=784, activation='relu')), # input layer \n",
        "    model.add(Dropout(0.1)), # set a drop out \n",
        "    model.add(Dense(100, activation='relu')), # hidden layer\n",
        "    model.add(Dropout(0.1)), # set a drop out \n",
        "    model.add(Dense(50, activation='relu')), # hidden layer\n",
        "    model.add(Dense(10, activation='sigmoid')) # output layer        \n",
        "    model.compile( # compile the model \n",
        "                  optimizer = 'adam', # uses stochaastic gradient descent, auto tunes itself\n",
        "                  loss = 'categorical_crossentropy', \n",
        "                  metrics = ['accuracy'] # for classification use accuracy\n",
        "                 )\n",
        "\n",
        "    return model\n",
        "\n",
        "seed = 7 \n",
        "np.random.seed(seed) # random seed for reproducibility\n",
        "model1 = KerasClassifier(build_fn=create_model)\n",
        "### set parameters to tune ### \n",
        "epochs = [10]\n",
        "batch_size = [5, 10, 20]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "grid = GridSearchCV(estimator=model1, param_grid=param_grid, verbose = 1)\n",
        "print('--- model runtime ---')\n",
        "%time grid.fit(X_train, y_train)\n",
        "### model metrics ###\n",
        "print('--- metrics ---')\n",
        "print(\"score:\", (grid.best_score_))\n",
        "print('--- best parameters ---')\n",
        "for param, value in grid.best_params_.items():\n",
        "    print('\\t{}: {}'.format(param, value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- model runtime ---\n",
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "9600/9600 [==============================] - 19s 2ms/step - loss: 2.2682 - accuracy: 0.6675\n",
            "Epoch 2/10\n",
            "9600/9600 [==============================] - 17s 2ms/step - loss: 0.5260 - accuracy: 0.8610\n",
            "Epoch 3/10\n",
            "9600/9600 [==============================] - 17s 2ms/step - loss: 0.4348 - accuracy: 0.8812\n",
            "Epoch 4/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3987 - accuracy: 0.8954\n",
            "Epoch 5/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3592 - accuracy: 0.9034\n",
            "Epoch 6/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3448 - accuracy: 0.9103\n",
            "Epoch 7/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3283 - accuracy: 0.9145\n",
            "Epoch 8/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3235 - accuracy: 0.9137\n",
            "Epoch 9/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3202 - accuracy: 0.9168\n",
            "Epoch 10/10\n",
            "9600/9600 [==============================] - 19s 2ms/step - loss: 0.3136 - accuracy: 0.9194\n",
            "2400/2400 [==============================] - 3s 1ms/step - loss: 0.2966 - accuracy: 0.9412\n",
            "Epoch 1/10\n",
            "9600/9600 [==============================] - 19s 2ms/step - loss: 2.2817 - accuracy: 0.6590\n",
            "Epoch 2/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.4689 - accuracy: 0.8764\n",
            "Epoch 3/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3850 - accuracy: 0.9000\n",
            "Epoch 4/10\n",
            "9600/9600 [==============================] - 20s 2ms/step - loss: 0.3597 - accuracy: 0.9105\n",
            "Epoch 5/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3321 - accuracy: 0.9184\n",
            "Epoch 6/10\n",
            "9600/9600 [==============================] - 19s 2ms/step - loss: 0.3054 - accuracy: 0.9226\n",
            "Epoch 7/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.2919 - accuracy: 0.9245\n",
            "Epoch 8/10\n",
            "9600/9600 [==============================] - 21s 2ms/step - loss: 0.2846 - accuracy: 0.9284\n",
            "Epoch 9/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.2932 - accuracy: 0.9275\n",
            "Epoch 10/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.2790 - accuracy: 0.9301\n",
            "2400/2400 [==============================] - 3s 1ms/step - loss: 0.2694 - accuracy: 0.9403\n",
            "Epoch 1/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 2.2483 - accuracy: 0.6342\n",
            "Epoch 2/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.5592 - accuracy: 0.8458\n",
            "Epoch 3/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.4627 - accuracy: 0.8727\n",
            "Epoch 4/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.4108 - accuracy: 0.8894\n",
            "Epoch 5/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.4086 - accuracy: 0.8901\n",
            "Epoch 6/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3859 - accuracy: 0.8994\n",
            "Epoch 7/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3716 - accuracy: 0.8995\n",
            "Epoch 8/10\n",
            "9600/9600 [==============================] - 17s 2ms/step - loss: 0.3573 - accuracy: 0.9019\n",
            "Epoch 9/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3591 - accuracy: 0.9006\n",
            "Epoch 10/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3508 - accuracy: 0.9054\n",
            "2400/2400 [==============================] - 3s 1ms/step - loss: 0.3149 - accuracy: 0.9233\n",
            "Epoch 1/10\n",
            "9600/9600 [==============================] - 19s 2ms/step - loss: 2.3643 - accuracy: 0.6243\n",
            "Epoch 2/10\n",
            "9600/9600 [==============================] - 17s 2ms/step - loss: 0.4797 - accuracy: 0.8679\n",
            "Epoch 3/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.4106 - accuracy: 0.8854\n",
            "Epoch 4/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3738 - accuracy: 0.8972\n",
            "Epoch 5/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3764 - accuracy: 0.8985\n",
            "Epoch 6/10\n",
            "9600/9600 [==============================] - 20s 2ms/step - loss: 0.3512 - accuracy: 0.9086\n",
            "Epoch 7/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3253 - accuracy: 0.9147\n",
            "Epoch 8/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3154 - accuracy: 0.9174\n",
            "Epoch 9/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3175 - accuracy: 0.9168\n",
            "Epoch 10/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3086 - accuracy: 0.9203\n",
            "2400/2400 [==============================] - 3s 1ms/step - loss: 0.2825 - accuracy: 0.9310\n",
            "Epoch 1/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 2.5713 - accuracy: 0.6462\n",
            "Epoch 2/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.5220 - accuracy: 0.8622\n",
            "Epoch 3/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.4023 - accuracy: 0.8938\n",
            "Epoch 4/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3683 - accuracy: 0.9038\n",
            "Epoch 5/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3424 - accuracy: 0.9139\n",
            "Epoch 6/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3284 - accuracy: 0.9209\n",
            "Epoch 7/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3245 - accuracy: 0.9209\n",
            "Epoch 8/10\n",
            "9600/9600 [==============================] - 19s 2ms/step - loss: 0.3215 - accuracy: 0.9223\n",
            "Epoch 9/10\n",
            "9600/9600 [==============================] - 19s 2ms/step - loss: 0.3016 - accuracy: 0.9275\n",
            "Epoch 10/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3014 - accuracy: 0.9320\n",
            "2400/2400 [==============================] - 3s 1ms/step - loss: 0.2435 - accuracy: 0.9442\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 2.5766 - accuracy: 0.6503\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4897 - accuracy: 0.8658\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.3840 - accuracy: 0.8936\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.3385 - accuracy: 0.9093\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 11s 2ms/step - loss: 0.3025 - accuracy: 0.9198\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2666 - accuracy: 0.9267\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2550 - accuracy: 0.9328\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2434 - accuracy: 0.9360\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2498 - accuracy: 0.9345\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2304 - accuracy: 0.9388\n",
            "1200/1200 [==============================] - 1s 1ms/step - loss: 0.2046 - accuracy: 0.9481\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 2.6995 - accuracy: 0.5711\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4869 - accuracy: 0.8620\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.3857 - accuracy: 0.8940\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.3259 - accuracy: 0.9112\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2966 - accuracy: 0.9212\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2741 - accuracy: 0.9261\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2751 - accuracy: 0.9263\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2496 - accuracy: 0.9350\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2462 - accuracy: 0.9380\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2400 - accuracy: 0.9352\n",
            "1200/1200 [==============================] - 1s 1ms/step - loss: 0.2045 - accuracy: 0.9471\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 2.7965 - accuracy: 0.5912\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4789 - accuracy: 0.8652\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.3513 - accuracy: 0.9044\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.3112 - accuracy: 0.9139\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2867 - accuracy: 0.9209\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 11s 2ms/step - loss: 0.2699 - accuracy: 0.9252\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2622 - accuracy: 0.9283\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2541 - accuracy: 0.9323\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2513 - accuracy: 0.9335\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2414 - accuracy: 0.9343\n",
            "1200/1200 [==============================] - 1s 1ms/step - loss: 0.2933 - accuracy: 0.9311\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 2.4302 - accuracy: 0.5954\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.5540 - accuracy: 0.8509\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4367 - accuracy: 0.8818\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.3716 - accuracy: 0.8982\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.3342 - accuracy: 0.9096\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.3155 - accuracy: 0.9150\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2852 - accuracy: 0.9220\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 11s 2ms/step - loss: 0.2804 - accuracy: 0.9243\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2714 - accuracy: 0.9244\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2702 - accuracy: 0.9276\n",
            "1200/1200 [==============================] - 1s 1ms/step - loss: 0.2583 - accuracy: 0.9298\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 3.0208 - accuracy: 0.6084\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.5136 - accuracy: 0.8681\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4020 - accuracy: 0.8924\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.3522 - accuracy: 0.9063\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.3233 - accuracy: 0.9114\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.3087 - accuracy: 0.9190\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2925 - accuracy: 0.9221\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2709 - accuracy: 0.9286\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2688 - accuracy: 0.9293\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2581 - accuracy: 0.9332\n",
            "1200/1200 [==============================] - 1s 1ms/step - loss: 0.2259 - accuracy: 0.9467\n",
            "Epoch 1/10\n",
            "2400/2400 [==============================] - 6s 2ms/step - loss: 2.7492 - accuracy: 0.6289\n",
            "Epoch 2/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.4869 - accuracy: 0.8650\n",
            "Epoch 3/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.3650 - accuracy: 0.8950\n",
            "Epoch 4/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2976 - accuracy: 0.9147\n",
            "Epoch 5/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2593 - accuracy: 0.9275\n",
            "Epoch 6/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2469 - accuracy: 0.9303\n",
            "Epoch 7/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2204 - accuracy: 0.9388\n",
            "Epoch 8/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2117 - accuracy: 0.9415\n",
            "Epoch 9/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.1937 - accuracy: 0.9467\n",
            "Epoch 10/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.1936 - accuracy: 0.9479\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.1864 - accuracy: 0.9510\n",
            "Epoch 1/10\n",
            "2400/2400 [==============================] - 6s 2ms/step - loss: 3.1312 - accuracy: 0.5777\n",
            "Epoch 2/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.5352 - accuracy: 0.8553\n",
            "Epoch 3/10\n",
            "2400/2400 [==============================] - 6s 3ms/step - loss: 0.4115 - accuracy: 0.8875\n",
            "Epoch 4/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.3328 - accuracy: 0.9080\n",
            "Epoch 5/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2922 - accuracy: 0.9207\n",
            "Epoch 6/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2665 - accuracy: 0.9281\n",
            "Epoch 7/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2438 - accuracy: 0.9335\n",
            "Epoch 8/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2330 - accuracy: 0.9354\n",
            "Epoch 9/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2218 - accuracy: 0.9415\n",
            "Epoch 10/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2083 - accuracy: 0.9443\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2147 - accuracy: 0.9433\n",
            "Epoch 1/10\n",
            "2400/2400 [==============================] - 6s 2ms/step - loss: 2.7395 - accuracy: 0.6203\n",
            "Epoch 2/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.5280 - accuracy: 0.8582\n",
            "Epoch 3/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.4015 - accuracy: 0.8923\n",
            "Epoch 4/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.3586 - accuracy: 0.9028\n",
            "Epoch 5/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.3153 - accuracy: 0.9154\n",
            "Epoch 6/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2911 - accuracy: 0.9202\n",
            "Epoch 7/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2738 - accuracy: 0.9245\n",
            "Epoch 8/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2572 - accuracy: 0.9295\n",
            "Epoch 9/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2455 - accuracy: 0.9321\n",
            "Epoch 10/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2277 - accuracy: 0.9371\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2067 - accuracy: 0.9473\n",
            "Epoch 1/10\n",
            "2400/2400 [==============================] - 6s 2ms/step - loss: 3.1836 - accuracy: 0.5202\n",
            "Epoch 2/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.5800 - accuracy: 0.8392\n",
            "Epoch 3/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.4348 - accuracy: 0.8847\n",
            "Epoch 4/10\n",
            "2400/2400 [==============================] - 6s 2ms/step - loss: 0.3601 - accuracy: 0.9024\n",
            "Epoch 5/10\n",
            "2400/2400 [==============================] - 6s 3ms/step - loss: 0.3131 - accuracy: 0.9140\n",
            "Epoch 6/10\n",
            "2400/2400 [==============================] - 6s 3ms/step - loss: 0.2673 - accuracy: 0.9258\n",
            "Epoch 7/10\n",
            "2400/2400 [==============================] - 6s 3ms/step - loss: 0.2546 - accuracy: 0.9322\n",
            "Epoch 8/10\n",
            "2400/2400 [==============================] - 6s 2ms/step - loss: 0.2337 - accuracy: 0.9349\n",
            "Epoch 9/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2247 - accuracy: 0.9388\n",
            "Epoch 10/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2068 - accuracy: 0.9430\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.1999 - accuracy: 0.9452\n",
            "Epoch 1/10\n",
            "2400/2400 [==============================] - 6s 2ms/step - loss: 3.4171 - accuracy: 0.5597\n",
            "Epoch 2/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.5539 - accuracy: 0.8530\n",
            "Epoch 3/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.4129 - accuracy: 0.8893\n",
            "Epoch 4/10\n",
            "2400/2400 [==============================] - 6s 2ms/step - loss: 0.3607 - accuracy: 0.8997\n",
            "Epoch 5/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.3173 - accuracy: 0.9130\n",
            "Epoch 6/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2800 - accuracy: 0.9237\n",
            "Epoch 7/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2715 - accuracy: 0.9261\n",
            "Epoch 8/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2480 - accuracy: 0.9334\n",
            "Epoch 9/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2405 - accuracy: 0.9347\n",
            "Epoch 10/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2316 - accuracy: 0.9376\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.1979 - accuracy: 0.9509\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 28.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3000/3000 [==============================] - 7s 2ms/step - loss: 2.5574 - accuracy: 0.6416\n",
            "Epoch 2/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.4511 - accuracy: 0.8740\n",
            "Epoch 3/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.3622 - accuracy: 0.8981\n",
            "Epoch 4/10\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.3076 - accuracy: 0.9116\n",
            "Epoch 5/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.2742 - accuracy: 0.9210\n",
            "Epoch 6/10\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.2560 - accuracy: 0.9276\n",
            "Epoch 7/10\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.2498 - accuracy: 0.9278\n",
            "Epoch 8/10\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.2320 - accuracy: 0.9329\n",
            "Epoch 9/10\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.2231 - accuracy: 0.9355\n",
            "Epoch 10/10\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.2036 - accuracy: 0.9438\n",
            "CPU times: user 34min, sys: 3min 8s, total: 37min 8s\n",
            "Wall time: 29min 19s\n",
            "--- metrics ---\n",
            "score: 0.9475333213806152\n",
            "--- best parameters ---\n",
            "\tbatch_size: 20\n",
            "\tepochs: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm3dfUka2vxB",
        "outputId": "9383a1f1-5a89-4464-a833-194276ebcc4e"
      },
      "source": [
        "from tensorflow import keras \n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.activations import relu, sigmoid\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "seed = 7\n",
        "np.random.seed(seed) # random seed for reproducability\n",
        "### create the model ###\n",
        "model = Sequential() # initiate the model \n",
        "model.add(Dense(50, input_dim=784, activation='relu')), # input layer, set dimension\n",
        "model.add(Dropout(0.1)), # set the drop out \n",
        "model.add(Dense(100, activation='relu')), # hidden layer\n",
        "model.add(Dropout(0.1)), # set the drop out \n",
        "model.add(Dense(50, activation='relu')), # hidden layer\n",
        "model.add(Dense(10, activation='sigmoid')) # output layer \n",
        "model.compile( # compile the model \n",
        "              optimizer = 'adam', \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy']\n",
        "              )\n",
        "### show summary ### \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_68 (Dense)             (None, 50)                39250     \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_69 (Dense)             (None, 100)               5100      \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 49,910\n",
            "Trainable params: 49,910\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLIavG9J3nSH",
        "outputId": "044e0614-3282-4e7a-d43a-264b8acecb4d"
      },
      "source": [
        "print('--- model runtime ---')\n",
        "%time history = model.fit(X_train, y_train, batch_size=20, epochs=10, validation_split=.1, verbose=False) # fit the model \n",
        "scores = model.evaluate(X_test, y_test) # get the model score from evaluation\n",
        "print(f'model accuracy = {scores[1]*100}') # show the models accuracy score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- model runtime ---\n",
            "CPU times: user 1min 4s, sys: 5.58 s, total: 1min 10s\n",
            "Wall time: 47.5 s\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1736 - accuracy: 0.9550\n",
            "model accuracy = 95.49999833106995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "pb2G77ka6N2s",
        "outputId": "6b8379e3-b262-4110-bd47-72bbe2de4a62"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "### plot the model loss ###\n",
        "### configure the plot ###\n",
        "print('--- model loss-MAE --- ')\n",
        "f, ax = plt.subplots(1, 1, figsize = (10, 7))\n",
        "ax1 = plt.plot(history.history['loss'], color=\"r\", label=\"loss-MSE\")\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- model loss-MAE --- \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbJGutZKhijy"
      },
      "source": [
        "##### RandomSearch CV "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "oBf5Ve-f6FZz",
        "outputId": "0cbc3565-aff1-4b7d-b994-5b3313b8f511"
      },
      "source": [
        "### parameter tuning options ###\n",
        "'''\n",
        "- tune 1-2 parameters at a time \n",
        "- add parameters to model function input\n",
        "- set the list of values for the parameter in the model \n",
        "- add the parameter to the param_grid dictionary\n",
        "'''\n",
        "# def create_model(optimizer='rmsprop', init='glorot_uniform',dropout_rate=0.0, weight_constraint=0, activation='relu', learn_rate=0.01, momentum=0, neurons=1)\n",
        "# optimizers = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "# init = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'] # network weight initializer, will change with choice of activation function \n",
        "# activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'], # controls the non-linearity of individual neurons and when to fire, 'sigmoid' last layer for 0-1 value outputs\n",
        "# epochs = [10, 50, 100] # no model input necessary, how many times the model will run \n",
        "# batch_size = [5, 10, 20] # no model input necessary, # of samples to run in each epoch\n",
        "# learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3] # combine with momentum, use SGD optimizer, how much to update the weight after each batch  \n",
        "# momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9] # combine with learn_rate, use SGD optimizer\n",
        "# optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
        "# weight_constraint = [1, 2, 3, 4, 5] # combine with dropout \n",
        "# dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] # combine with weight_constraint\n",
        "# neurons = [1, 5, 10, 15, 20, 25, 30]\n",
        "# param_grid = dict(batch_size=batch_size, epochs=epochs, batch_size=batch_size, learn_rate=learn_rate, momentum=momentum, weight_constraint=weight_constraint, dropout_rate=dropout_rate, neurons)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n- tune 1-2 parameters at a time \\n- add parameters to model function input\\n- set the list of values for the parameter in the model \\n- add the parameter to the param_grid dictionary\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzCl1nVxchYW",
        "outputId": "94e413bf-9edd-4481-e190-0c5d0dc40bb2"
      },
      "source": [
        "from tensorflow import keras \n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from keras.optimizers import Adam, Nadam, RMSprop\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.activations import relu, sigmoid\n",
        "from sklearn.model_selection import cross_val_score\n",
        "### create a model function ### \n",
        "def create_model(optimizers):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(50, input_dim=784, activation='relu')), # input layer \n",
        "    model.add(Dropout(0.1)), # set the drop out \n",
        "    model.add(Dense(100, activation='relu')), # hidden layer\n",
        "    model.add(Dropout(0.1)), # set the drop out \n",
        "    model.add(Dense(50, activation='relu')), # hidden layer\n",
        "    model.add(Dense(10, activation='sigmoid')) # output layer        \n",
        "    model.compile(\n",
        "                  optimizer = optimizers, # tuning \n",
        "                  loss = 'categorical_crossentropy', \n",
        "                  metrics = ['accuracy'] # for classification use accuracy\n",
        "                 )\n",
        "\n",
        "    return model\n",
        "\n",
        "seed = 7\n",
        "np.random.seed(seed) # random seed for reproducibility\n",
        "model1 = KerasClassifier(build_fn=create_model) # initiate the model\n",
        "### set parameters to tune ### \n",
        "optimizers = ['rmsprop', 'adam', 'Nadam'] # tune new parameter \n",
        "epochs = [10] # set the epoch \n",
        "batch_size = [20] # set the batch size\n",
        "param_grid = dict(optimizers = optimizers, batch_size = batch_size, epochs = epochs) # create the param dict\n",
        "random = RandomizedSearchCV(model1, param_distributions = param_grid, n_jobs=-1, verbose=1) # initiate the model \n",
        "print('--- model runtime ---')\n",
        "%time random.fit(X_train, y_train) # fit the data\n",
        "### model metrics ###\n",
        "print('--- metrics ---')\n",
        "print(\"score:\", (random.best_score_)) # show the score \n",
        "print('--- best parameters ---')\n",
        "for param, value in random.best_params_.items(): # show the best params\n",
        "    print('\\t{}: {}'.format(param, value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- model runtime ---\n",
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 10.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0491 - accuracy: 0.6287\n",
            "Epoch 2/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.4446 - accuracy: 0.8787\n",
            "Epoch 3/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.3259 - accuracy: 0.9128\n",
            "Epoch 4/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.2692 - accuracy: 0.9264\n",
            "Epoch 5/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.2353 - accuracy: 0.9355\n",
            "Epoch 6/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.2091 - accuracy: 0.9420\n",
            "Epoch 7/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.2027 - accuracy: 0.9449\n",
            "Epoch 8/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.1890 - accuracy: 0.9476\n",
            "Epoch 9/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.1747 - accuracy: 0.9530\n",
            "Epoch 10/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.1659 - accuracy: 0.9551\n",
            "CPU times: user 1min 17s, sys: 7.38 s, total: 1min 24s\n",
            "Wall time: 11min 29s\n",
            "--- metrics ---\n",
            "score: 0.9483500123023987\n",
            "--- best parameters ---\n",
            "\toptimizers: adam\n",
            "\tepochs: 10\n",
            "\tbatch_size: 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkBtpmPu3BBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61e7d90-4f49-4fa6-e43b-5fac3e049298"
      },
      "source": [
        "from tensorflow import keras \n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.activations import relu, sigmoid\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "seed = 7\n",
        "np.random.seed(seed) # random seed for reproducibility\n",
        "### create the model ### \n",
        "model = Sequential() # initiate the model \n",
        "model.add(Dense(50, input_dim=784, activation='relu')), # input layer \n",
        "model.add(Dropout(0.1)), # set drop out \n",
        "model.add(Dense(100, activation='relu')), # hidden layer\n",
        "model.add(Dropout(0.1)), # set drop out \n",
        "model.add(Dense(50, activation='relu')), # hidden layer\n",
        "model.add(Dense(10, activation='sigmoid')) # output layer \n",
        "model.compile( # compile the model \n",
        "              optimizer = 'adam', \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy']\n",
        "              )\n",
        "### show summary ### \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_84 (Dense)             (None, 50)                39250     \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_85 (Dense)             (None, 100)               5100      \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_86 (Dense)             (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_87 (Dense)             (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 49,910\n",
            "Trainable params: 49,910\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abntX5ei2i5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "965d81a7-7e95-4c50-8836-a893b3ee2d44"
      },
      "source": [
        "print('--- model runtime ---')\n",
        "%time history = model.fit(X_train, y_train, batch_size=20, epochs=10, validation_split=.1, verbose=False) # fit the model \n",
        "scores = model.evaluate(X_test, y_test) # get the model score from evaluation\n",
        "print(f'model accuracy = {scores[1]*100}') # show the models accuracy score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- model runtime ---\n",
            "CPU times: user 1min 2s, sys: 5.62 s, total: 1min 7s\n",
            "Wall time: 45.3 s\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1824 - accuracy: 0.9544\n",
            "model accuracy = 95.44000029563904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKux3Dvg6Qld",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "0dac9bed-c3ed-4c3e-80fb-d47f00703860"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "### plot the model loss ###\n",
        "### configure the plot ###\n",
        "print('--- model loss-MAE --- ')\n",
        "f, ax = plt.subplots(1, 1, figsize = (10, 7))\n",
        "ax1 = plt.plot(history.history['loss'], color=\"r\", label=\"loss-MSE\")\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- model loss-MAE --- \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}