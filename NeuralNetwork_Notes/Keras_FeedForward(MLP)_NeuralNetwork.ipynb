{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_FeedForward(MLP)_NeuralNetwork.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "k8oOsLF4havx",
        "gbJGutZKhijy"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFM5sl2ef0Cg"
      },
      "source": [
        "## Feed Forward (MLP) Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHYXNoDvORIF"
      },
      "source": [
        "### Neural Networks\n",
        "#### Neural networks are a series of algorithms that identify underlying relationships in a set of data. These algorithms are heavily based on the way a human brain operates. These networks can adapt to changing input and generate the best result without the requirement to redesign the output criteria.  Deep learning algorithms are based on neural networks.\n",
        "\n",
        "#### Neural Networks Components:\n",
        "\n",
        "- an input layer that receives data and pass it on\n",
        "- a hidden layer\n",
        "- an output layer\n",
        "- weights between the layers\n",
        "- a deliberate activation function for every hidden layer\n",
        "\n",
        "#### Pros \n",
        "- \n",
        "-\n",
        "\n",
        "#### Cons\n",
        "- \n",
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhRHMqRaQfiG"
      },
      "source": [
        "### Model Set Up\n",
        "\n",
        "#### Steps\n",
        " - load the data\n",
        " - inspect, clean, organize data\n",
        " - check for, handle outliers \n",
        " - encode data if necessary \n",
        " - set features and target \n",
        " - train, test split the data \n",
        " - scale the data if necessary \n",
        " - build, compile the model, fit the data, evaluate the model \n",
        " - run metrics, analyze, view results, adjust parameters, repeat until satisfied... \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hmqr8qAMLuE"
      },
      "source": [
        "### Neural Network Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9Z_XK3rO7H6"
      },
      "source": [
        "#### Multilayer Perceptrons (MLP), feed forward\n",
        "1 single neuron model that is a precursor to a larger neural network of neurons\n",
        " - feedforward, often need back-propagation, which provides the network with corresponding set of inputs and outputs. When the input data is transmitted into the neuron, it is processed, and an output is generated.\n",
        " - 3 layers, nodes/input layer, hidden layer, output layer\n",
        " - in hidden and the output layers, every node is considered as a neuron with a nonlinear activation function\n",
        " - supervised learning technique called backpropagation for training, adjusts weights of neurons\n",
        " - most ideal for projects involving tabular datasets, classification prediction problems, and regression prediction problems\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUXplGBBRmeD"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCbiZ7J-V55T"
      },
      "source": [
        "#### Import + Inspect "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThIRPgzSjP1T"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist # load the fashion-MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data() # split data for X train, y train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YltWjPbwcDlT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c563d4c4-d0db-447a-cd88-e1eadff208f6"
      },
      "source": [
        "X_train[25] # show the array for 25"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  83,\n",
              "         91, 143, 255, 190,  91,  50,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   9,  49, 180, 246,\n",
              "        253, 253, 253, 253, 253, 220, 154,  17,   3,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  46, 107, 178, 253, 253, 253,\n",
              "        253, 253, 253, 253, 253, 253, 253, 253, 126,  45,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 107, 253, 253, 253, 253, 223,\n",
              "        220, 220, 220, 220, 245, 253, 253, 253, 253, 106,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 107, 173, 253, 229, 129,  12,\n",
              "          0,   0,   0,   0, 110, 253, 253, 253, 253, 106,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  17,  14,  40,  32,   0,   0,\n",
              "          0,   0,   0,   0,  57, 253, 253, 253, 242,  85,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   5, 139, 224, 253, 253, 253, 105,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  65, 178, 253, 253, 253, 253, 219,  24,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         97, 250, 253, 253, 253, 253, 127,  47,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 125,\n",
              "        250, 253, 253, 253, 245, 171,  33,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   5,  41, 217, 253,\n",
              "        253, 250, 245, 245, 115,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 124, 253, 253, 253,\n",
              "        192, 105,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  11,  47, 220, 253, 253, 188,\n",
              "         25,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 107, 253, 253, 253, 189,  13,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  41, 225, 253, 253, 186,  22,   0,\n",
              "          0,   0,   0,   0,  31,  42, 174, 205, 205, 205, 193,  58,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,  48, 218, 253, 253, 253, 150,  59,   0,\n",
              "          0, 128, 131, 131, 222, 253, 253, 253, 253, 253,  94,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,  12, 152, 253, 253, 253, 253, 236, 222,\n",
              "        222, 252, 253, 253, 253, 253, 253, 253, 253, 253, 122,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   7, 167, 253, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 253, 253, 253, 253, 124, 106,   7,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  76, 188, 253, 253, 253, 253,\n",
              "        253, 253, 253, 224,  57,  15,  15,  15,   2,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  12,  89, 121, 253, 253,\n",
              "        151,  89,  89,  55,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "xsEHE1mhb9JN",
        "outputId": "d8f6848c-7a82-4675-ed2e-70089edc0719"
      },
      "source": [
        "### show what image the array makes ###\n",
        "import matplotlib.pyplot as plt \n",
        "plt.imshow(X_train[25], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6f36fd8128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAORklEQVR4nO3df4xVdXrH8c9TyqKB/QNWS0ZQ2UWi2TSUbYgxqTQSsquVGCBGA1GjlGT8Y42LadLBbRRQ1phaa8I/xFkhTBvqipFVszFhLWCxmhhHYhWd7koRBTIwKiYzmOgqPP1jDmbAOd873HPOPRee9yuZzL3nmXPOkxs+nHPPr6+5uwCc//6s7gYAtAZhB4Ig7EAQhB0IgrADQfx5K1dmZhz6Byrm7jba9EJbdjO7wcz+YGb7zGxVkWUBqJY1e57dzMZJ+qOkn0o6JOlNScvc/f3EPGzZgYpVsWW/WtI+d9/v7n+S9BtJiwosD0CFioR9mqSDI94fyqadxsw6zazXzHoLrAtAQZUfoHP3bkndErvxQJ2KbNkPS7p0xPvp2TQAbahI2N+UNMvMfmhm35O0VNKL5bQFoGxN78a7+zdmdo+k7ZLGSdrk7u+V1hmAUjV96q2plfGdHahcJRfVADh3EHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQREuHbEbr3Xzzzcn6BRdckKzPnTs3WV+5cmWyvmvXrtzaxo0bk/P29fUl63v27EnWcTq27EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBKO4toELL7wwWb/yyiuT9Ycffji3tmDBguS8EyZMSNbr9OGHHybrO3fuTNa7urpya4ODg8l5T5w4kay3s7xRXAtdVGNmByQNSToh6Rt3T1+BAaA2ZVxBN9/dPy1hOQAqxHd2IIiiYXdJvzezt8ysc7Q/MLNOM+s1s96C6wJQQNHd+Gvd/bCZ/YWkl83sf91998g/cPduSd0SB+iAOhXasrv74ez3gKTfSrq6jKYAlK/psJvZRDP7/qnXkn4maW9ZjQEoV9Pn2c3sRxremkvDXwf+w91/1WCe83I3fvbs2cn6vHnzkvXrr78+WV+4cOFZ94S0tWvXJuvbtm1L1vfubd/tWunn2d19v6S/arojAC3FqTcgCMIOBEHYgSAIOxAEYQeC4FHSJWh0am39+vUt6uS7Pv7442S9zls5Ozo6kvVGj7kuYvXq1cn6J598kqy386m3PGzZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIzrO3wPPPP5+sL168OFk/cuRIsv7UU0/l1h577LHkvMePH0/Wq3Tvvfcm60888USLOomBLTsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBMGQzSWYPHlyst7onvFLLrkkWf/yyy+T9QMHDiTr7eqaa65J1l977bXK1v3FF18k6ytWrEjWn3322TLbKVXeo6TZsgNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAENzPXoLPP/+80PyDg4MlddJ648ePT9YfeeSR3Nott9xSdjtj1tXVlay383n0ZjXcspvZJjMbMLO9I6ZNMbOXzeyD7Hf6qhIAtRvLbvxmSTecMW2VpB3uPkvSjuw9gDbWMOzuvlvSsTMmL5LUk73ukZR+rhKA2jX7nX2qu/dnr49Impr3h2bWKamzyfUAKEnhA3Tu7qkbXNy9W1K3dP7eCAOcC5o99XbUzDokKfs9UF5LAKrQbNhflHRn9vpOSS+U0w6AqjS8n93MnpZ0naSLJB2VtFrS85K2SrpM0keSbnX3Mw/ijbYsduPPMfPnz0/W77vvvmR94cKFZbZzVvbv359bmzdvXnLeRs/qb2d597M3/M7u7stySgsKdQSgpbhcFgiCsANBEHYgCMIOBEHYgSC4xTW45cuXJ+tPPvlksj5u3Lgy2zkrDz30ULKeGir7XD611iy27EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBOfZzwOzZ8/OrS1atCg57wMPPJCsV3kevdFQ1C+99FKy3tPTk6yfq0NZV4UtOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4E0fBR0qWujEdJj6rRsMczZ85M1l94If+x/VdccUVTPZ1y4sSJZP3rr79uetkPPvhgsv744483vezI8h4lzZYdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4LgfvY20NXVlayvXbu2snW/+uqryfozzzyTrG/YsKHMdlChhlt2M9tkZgNmtnfEtDVmdtjM3s5+bqy2TQBFjWU3frOkG0aZ/oS7z8l+0o8UAVC7hmF3992SjrWgFwAVKnKA7h4zeyfbzZ+c90dm1mlmvWbWW2BdAApqNuwbJM2UNEdSv6TcOxbcvdvd57r73CbXBaAETYXd3Y+6+wl3Pynp15KuLrctAGVrKuxm1jHi7RJJe/P+FkB7aHie3cyelnSdpIvM7JCk1ZKuM7M5klzSAUl3V9hj25s4cWKy3uie8rvuuqvEbk63a9euZP2OO+5I1vv7+8tsBzVqGHZ3XzbK5I0V9AKgQlwuCwRB2IEgCDsQBGEHgiDsQBDc4lqCRqfO1q9fX+n6X3nlldzakiVLkvMODQ2V3A3aFVt2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCIZvH6Kqrrsqtbd++PTnv9OnTC617x44dyfrtt9+eWxsYGCi07ipdfvnlyXqjW4fXrVtXaPlFHD9+PFm///77k/XXX3+9zHZOw5DNQHCEHQiCsANBEHYgCMIOBEHYgSAIOxAE97Nn5syZk6xv3bo1t1b0PHoj+/btS9ZnzZqVWyt6nn3NmjXJ+rhx45pe9m233ZasV3mevKjly5cn61WeR28WW3YgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCILz7JlG57J37tyZW5s5c2bZ7Zzm7rvTI2LfeuutubXBwcFC677sssuSdbNRb50+702bNq3uFs5awy27mV1qZrvM7H0ze8/MfpFNn2JmL5vZB9nvydW3C6BZY9mN/0bSP7j7jyVdI+nnZvZjSask7XD3WZJ2ZO8BtKmGYXf3fnffk70ektQnaZqkRZJ6sj/rkbS4qiYBFHdW39nNbIakn0h6Q9JUd+/PSkckTc2Zp1NSZ/MtAijDmI/Gm9kkSc9JWunupx318eGnVo76MEl373b3ue4+t1CnAAoZU9jNbLyGg77F3bdlk4+aWUdW75DUvo8xBdD4UdI2fG6lR9Ixd185Yvpjkj5z90fNbJWkKe7+jw2Wdc4+SnrChAm5tc2bNyfnTZ0aQz1Wr16drH/22WfJ+qZNm5L1r7766qx7Kkveo6TH8p39byTdIeldM3s7m/ZLSY9K2mpmKyR9JIl/0UAbaxh2d/9vSXlXTiwotx0AVeFyWSAIwg4EQdiBIAg7EARhB4LgFtcxSp033bJlS3Leiy++OFmfP39+Uz2dCw4ePJhbW7p0aXLevr6+stv51tDQULJ+8uTJytZdF7bsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxBEw/vZS13ZOXw/exGTJk1K1m+66aZkfcaMGcn6unXrzralb3V3dyfru3fvbnrZkrR///7c2htvvFFo2Rhd3v3sbNmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjOswPnGc6zA8ERdiAIwg4EQdiBIAg7EARhB4Ig7EAQDcNuZpea2S4ze9/M3jOzX2TT15jZYTN7O/u5sfp2ATSr4UU1ZtYhqcPd95jZ9yW9JWmxhsdjP+7u/zLmlXFRDVC5vItqxjI+e7+k/uz1kJn1SZpWbnsAqnZW39nNbIakn0g69Tyhe8zsHTPbZGaTc+bpNLNeM+st1CmAQsZ8bbyZTZL0X5J+5e7bzGyqpE8luaSHNbyr//cNlsFuPFCxvN34MYXdzMZL+p2k7e7+r6PUZ0j6nbv/ZYPlEHagYk3fCGNmJmmjpL6RQc8O3J2yRNLeok0CqM5YjsZfK+lVSe9KOjWO7S8lLZM0R8O78Qck3Z0dzEstiy07ULFCu/FlIexA9bifHQiOsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EETDB06W7FNJH414f1E2rR21a2/t2pdEb80qs7fL8wotvZ/9Oys363X3ubU1kNCuvbVrXxK9NatVvbEbDwRB2IEg6g57d83rT2nX3tq1L4nemtWS3mr9zg6gderesgNoEcIOBFFL2M3sBjP7g5ntM7NVdfSQx8wOmNm72TDUtY5Pl42hN2Bme0dMm2JmL5vZB9nvUcfYq6m3thjGOzHMeK2fXd3Dn7f8O7uZjZP0R0k/lXRI0puSlrn7+y1tJIeZHZA0191rvwDDzP5W0nFJ/3ZqaC0z+2dJx9z90ew/ysnu3tUmva3RWQ7jXVFvecOM36UaP7syhz9vRh1b9qsl7XP3/e7+J0m/kbSohj7anrvvlnTsjMmLJPVkr3s0/I+l5XJ6awvu3u/ue7LXQ5JODTNe62eX6Ksl6gj7NEkHR7w/pPYa790l/d7M3jKzzrqbGcXUEcNsHZE0tc5mRtFwGO9WOmOY8bb57JoZ/rwoDtB917Xu/teS/k7Sz7Pd1bbkw9/B2unc6QZJMzU8BmC/pMfrbCYbZvw5SSvdfXBkrc7PbpS+WvK51RH2w5IuHfF+ejatLbj74ez3gKTfavhrRzs5emoE3ez3QM39fMvdj7r7CXc/KenXqvGzy4YZf07SFnfflk2u/bMbra9WfW51hP1NSbPM7Idm9j1JSyW9WEMf32FmE7MDJzKziZJ+pvYbivpFSXdmr++U9EKNvZymXYbxzhtmXDV/drUPf+7uLf+RdKOGj8j/n6R/qqOHnL5+JOl/sp/36u5N0tMa3q37WsPHNlZI+oGkHZI+kPSfkqa0UW//ruGhvd/RcLA6aurtWg3vor8j6e3s58a6P7tEXy353LhcFgiCA3RAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EMT/A9SJgeRGoKlIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7AXVEyNPKBj"
      },
      "source": [
        "#### Reshape + Encode "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z4k1D0uekFE"
      },
      "source": [
        "### reshape the data ### \n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_GOvh2rVjBm"
      },
      "source": [
        "### set X variable types to float ### \n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "### set classes, convert vectors to binary class matrix ###\n",
        "num_classes = 10\n",
        "from tensorflow import keras \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEQzqEqfO4ha"
      },
      "source": [
        "#### (MLP) Feed Forward Neural Network\n",
        " - GridSearch CV \n",
        " - RandomizedSearch CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CYBuj9ymGuS",
        "outputId": "3eb40404-2e24-4ff7-ed6b-4236be153756"
      },
      "source": [
        "from tensorflow import keras \n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.activations import relu, sigmoid\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "seed = 7\n",
        "np.random.seed(seed) # random seed for reproducability\n",
        "### create the model ###\n",
        "model = Sequential() # initiate the model \n",
        "model.add(Dense(50, input_dim=784, activation='relu')), # input layer, set dimension\n",
        "model.add(Dropout(0.1)), # set a drop out \n",
        "model.add(Dense(100, activation='relu')), # hidden layer\n",
        "model.add(Dropout(0.1)), # set a drop out \n",
        "model.add(Dense(50, activation='relu')), # hidden layer\n",
        "model.add(Dense(10, activation='sigmoid')) # output layer \n",
        "model.compile( # compile the model \n",
        "              optimizer = 'adam', \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy']\n",
        "              )\n",
        "### show summary ### \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 50)                39250     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               5100      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 49,910\n",
            "Trainable params: 49,910\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kkpHnIlm_VO",
        "outputId": "a0e473f2-f73e-4a0c-f7a6-1f8c9c3f8bbd"
      },
      "source": [
        "print('--- model runtime ---')\n",
        "%time history = model.fit(X_train, y_train, batch_size=20, epochs=50, validation_split=.1, verbose=False) # fit the model \n",
        "scores = model.evaluate(X_test, y_test) # get the model score from evaluation\n",
        "print(f'model accuracy = {scores[1]*100}') # show the models accuracy score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- model runtime ---\n",
            "CPU times: user 5min 2s, sys: 26.4 s, total: 5min 28s\n",
            "Wall time: 3min 37s\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2164 - accuracy: 0.9577\n",
            "model accuracy = 95.77000141143799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifq1RQ0JmNwh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "b448ed67-98e7-4c8c-9e46-837f27d9d7b6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "### plot the loss-MSE value ###\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8oOsLF4havx"
      },
      "source": [
        "##### GridSearch CV "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "YvOglyabxDUO",
        "outputId": "a7181ce2-df5b-4980-e4bb-c5e41e294424"
      },
      "source": [
        "### parameter tuning options ###\n",
        "'''\n",
        "- tune 1-2 parameters at a time \n",
        "- add parameters to model function input\n",
        "- set the list of values for the parameter in the model \n",
        "- add the parameter to the param_grid dictionary\n",
        "'''\n",
        "# def create_model(optimizer='rmsprop', init='glorot_uniform',dropout_rate=0.0, weight_constraint=0, activation='relu', learn_rate=0.01, momentum=0, neurons=1)\n",
        "# optimizers = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "# init = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'] # network weight initializer, will change with choice of activation function \n",
        "# activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'], # controls the non-linearity of individual neurons and when to fire, 'sigmoid' last layer for 0-1 value outputs\n",
        "# epochs = [10, 50, 100] # no model input necessary, how many times the model will run \n",
        "# batch_size = [5, 10, 20] # no model input necessary, # of samples to run in each epoch\n",
        "# learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3] # combine with momentum, use SGD optimizer, how much to update the weight after each batch  \n",
        "# momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9] # combine with learn_rate, use SGD optimizer\n",
        "# optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
        "# weight_constraint = [1, 2, 3, 4, 5] # combine with dropout \n",
        "# dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] # combine with weight_constraint\n",
        "# neurons = [1, 5, 10, 15, 20, 25, 30]\n",
        "# param_grid = dict(batch_size=batch_size, epochs=epochs, batch_size=batch_size, learn_rate=learn_rate, momentum=momentum, weight_constraint=weight_constraint, dropout_rate=dropout_rate, neurons)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n- tune 1-2 parameters at a time \\n- add parameters to model function input\\n- set the list of values for the parameter in the model \\n- add the parameter to the param_grid dictionary\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALt54gcLe_P1",
        "outputId": "b5983b80-03f9-4d21-fb85-a30487cb618a"
      },
      "source": [
        "from tensorflow import keras \n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.activations import relu, sigmoid\n",
        "from sklearn.model_selection import cross_val_score\n",
        "### create model function ###\n",
        "def create_model():\n",
        "    model = Sequential() # initiate the model \n",
        "    model.add(Dense(50, input_dim=784, activation='relu')), # input layer \n",
        "    model.add(Dropout(0.1)), # set a drop out \n",
        "    model.add(Dense(100, activation='relu')), # hidden layer\n",
        "    model.add(Dropout(0.1)), # set a drop out \n",
        "    model.add(Dense(50, activation='relu')), # hidden layer\n",
        "    model.add(Dense(10, activation='sigmoid')) # output layer        \n",
        "    model.compile( # compile the model \n",
        "                  optimizer = 'adam', # uses stochaastic gradient descent, auto tunes itself\n",
        "                  loss = 'categorical_crossentropy', \n",
        "                  metrics = ['accuracy'] # for classification use accuracy\n",
        "                 )\n",
        "\n",
        "    return model\n",
        "\n",
        "seed = 7 \n",
        "np.random.seed(seed) # random seed for reproducibility\n",
        "model1 = KerasClassifier(build_fn=create_model)\n",
        "### set parameters to tune ### \n",
        "epochs = [10]\n",
        "batch_size = [5, 10, 20]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "grid = GridSearchCV(estimator=model1, param_grid=param_grid, verbose = 1)\n",
        "print('--- model runtime ---')\n",
        "%time grid.fit(X_train, y_train)\n",
        "### model metrics ###\n",
        "print('--- metrics ---')\n",
        "print(\"score:\", (grid.best_score_))\n",
        "print('--- best parameters ---')\n",
        "for param, value in grid.best_params_.items():\n",
        "    print('\\t{}: {}'.format(param, value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- model runtime ---\n",
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "9600/9600 [==============================] - 19s 2ms/step - loss: 2.2682 - accuracy: 0.6675\n",
            "Epoch 2/10\n",
            "9600/9600 [==============================] - 17s 2ms/step - loss: 0.5260 - accuracy: 0.8610\n",
            "Epoch 3/10\n",
            "9600/9600 [==============================] - 17s 2ms/step - loss: 0.4348 - accuracy: 0.8812\n",
            "Epoch 4/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3987 - accuracy: 0.8954\n",
            "Epoch 5/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3592 - accuracy: 0.9034\n",
            "Epoch 6/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3448 - accuracy: 0.9103\n",
            "Epoch 7/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3283 - accuracy: 0.9145\n",
            "Epoch 8/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3235 - accuracy: 0.9137\n",
            "Epoch 9/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3202 - accuracy: 0.9168\n",
            "Epoch 10/10\n",
            "9600/9600 [==============================] - 19s 2ms/step - loss: 0.3136 - accuracy: 0.9194\n",
            "2400/2400 [==============================] - 3s 1ms/step - loss: 0.2966 - accuracy: 0.9412\n",
            "Epoch 1/10\n",
            "9600/9600 [==============================] - 19s 2ms/step - loss: 2.2817 - accuracy: 0.6590\n",
            "Epoch 2/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.4689 - accuracy: 0.8764\n",
            "Epoch 3/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3850 - accuracy: 0.9000\n",
            "Epoch 4/10\n",
            "9600/9600 [==============================] - 20s 2ms/step - loss: 0.3597 - accuracy: 0.9105\n",
            "Epoch 5/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3321 - accuracy: 0.9184\n",
            "Epoch 6/10\n",
            "9600/9600 [==============================] - 19s 2ms/step - loss: 0.3054 - accuracy: 0.9226\n",
            "Epoch 7/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.2919 - accuracy: 0.9245\n",
            "Epoch 8/10\n",
            "9600/9600 [==============================] - 21s 2ms/step - loss: 0.2846 - accuracy: 0.9284\n",
            "Epoch 9/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.2932 - accuracy: 0.9275\n",
            "Epoch 10/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.2790 - accuracy: 0.9301\n",
            "2400/2400 [==============================] - 3s 1ms/step - loss: 0.2694 - accuracy: 0.9403\n",
            "Epoch 1/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 2.2483 - accuracy: 0.6342\n",
            "Epoch 2/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.5592 - accuracy: 0.8458\n",
            "Epoch 3/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.4627 - accuracy: 0.8727\n",
            "Epoch 4/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.4108 - accuracy: 0.8894\n",
            "Epoch 5/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.4086 - accuracy: 0.8901\n",
            "Epoch 6/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3859 - accuracy: 0.8994\n",
            "Epoch 7/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3716 - accuracy: 0.8995\n",
            "Epoch 8/10\n",
            "9600/9600 [==============================] - 17s 2ms/step - loss: 0.3573 - accuracy: 0.9019\n",
            "Epoch 9/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3591 - accuracy: 0.9006\n",
            "Epoch 10/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3508 - accuracy: 0.9054\n",
            "2400/2400 [==============================] - 3s 1ms/step - loss: 0.3149 - accuracy: 0.9233\n",
            "Epoch 1/10\n",
            "9600/9600 [==============================] - 19s 2ms/step - loss: 2.3643 - accuracy: 0.6243\n",
            "Epoch 2/10\n",
            "9600/9600 [==============================] - 17s 2ms/step - loss: 0.4797 - accuracy: 0.8679\n",
            "Epoch 3/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.4106 - accuracy: 0.8854\n",
            "Epoch 4/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3738 - accuracy: 0.8972\n",
            "Epoch 5/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3764 - accuracy: 0.8985\n",
            "Epoch 6/10\n",
            "9600/9600 [==============================] - 20s 2ms/step - loss: 0.3512 - accuracy: 0.9086\n",
            "Epoch 7/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3253 - accuracy: 0.9147\n",
            "Epoch 8/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3154 - accuracy: 0.9174\n",
            "Epoch 9/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3175 - accuracy: 0.9168\n",
            "Epoch 10/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3086 - accuracy: 0.9203\n",
            "2400/2400 [==============================] - 3s 1ms/step - loss: 0.2825 - accuracy: 0.9310\n",
            "Epoch 1/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 2.5713 - accuracy: 0.6462\n",
            "Epoch 2/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.5220 - accuracy: 0.8622\n",
            "Epoch 3/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.4023 - accuracy: 0.8938\n",
            "Epoch 4/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3683 - accuracy: 0.9038\n",
            "Epoch 5/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3424 - accuracy: 0.9139\n",
            "Epoch 6/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3284 - accuracy: 0.9209\n",
            "Epoch 7/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3245 - accuracy: 0.9209\n",
            "Epoch 8/10\n",
            "9600/9600 [==============================] - 19s 2ms/step - loss: 0.3215 - accuracy: 0.9223\n",
            "Epoch 9/10\n",
            "9600/9600 [==============================] - 19s 2ms/step - loss: 0.3016 - accuracy: 0.9275\n",
            "Epoch 10/10\n",
            "9600/9600 [==============================] - 18s 2ms/step - loss: 0.3014 - accuracy: 0.9320\n",
            "2400/2400 [==============================] - 3s 1ms/step - loss: 0.2435 - accuracy: 0.9442\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 2.5766 - accuracy: 0.6503\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4897 - accuracy: 0.8658\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.3840 - accuracy: 0.8936\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.3385 - accuracy: 0.9093\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 11s 2ms/step - loss: 0.3025 - accuracy: 0.9198\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2666 - accuracy: 0.9267\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2550 - accuracy: 0.9328\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2434 - accuracy: 0.9360\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2498 - accuracy: 0.9345\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2304 - accuracy: 0.9388\n",
            "1200/1200 [==============================] - 1s 1ms/step - loss: 0.2046 - accuracy: 0.9481\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 2.6995 - accuracy: 0.5711\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4869 - accuracy: 0.8620\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.3857 - accuracy: 0.8940\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.3259 - accuracy: 0.9112\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2966 - accuracy: 0.9212\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2741 - accuracy: 0.9261\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2751 - accuracy: 0.9263\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2496 - accuracy: 0.9350\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2462 - accuracy: 0.9380\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2400 - accuracy: 0.9352\n",
            "1200/1200 [==============================] - 1s 1ms/step - loss: 0.2045 - accuracy: 0.9471\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 2.7965 - accuracy: 0.5912\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4789 - accuracy: 0.8652\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.3513 - accuracy: 0.9044\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.3112 - accuracy: 0.9139\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2867 - accuracy: 0.9209\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 11s 2ms/step - loss: 0.2699 - accuracy: 0.9252\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2622 - accuracy: 0.9283\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2541 - accuracy: 0.9323\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2513 - accuracy: 0.9335\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2414 - accuracy: 0.9343\n",
            "1200/1200 [==============================] - 1s 1ms/step - loss: 0.2933 - accuracy: 0.9311\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 2.4302 - accuracy: 0.5954\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.5540 - accuracy: 0.8509\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4367 - accuracy: 0.8818\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.3716 - accuracy: 0.8982\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.3342 - accuracy: 0.9096\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.3155 - accuracy: 0.9150\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2852 - accuracy: 0.9220\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 11s 2ms/step - loss: 0.2804 - accuracy: 0.9243\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2714 - accuracy: 0.9244\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2702 - accuracy: 0.9276\n",
            "1200/1200 [==============================] - 1s 1ms/step - loss: 0.2583 - accuracy: 0.9298\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 3.0208 - accuracy: 0.6084\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.5136 - accuracy: 0.8681\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4020 - accuracy: 0.8924\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.3522 - accuracy: 0.9063\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.3233 - accuracy: 0.9114\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.3087 - accuracy: 0.9190\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2925 - accuracy: 0.9221\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2709 - accuracy: 0.9286\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2688 - accuracy: 0.9293\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 9s 2ms/step - loss: 0.2581 - accuracy: 0.9332\n",
            "1200/1200 [==============================] - 1s 1ms/step - loss: 0.2259 - accuracy: 0.9467\n",
            "Epoch 1/10\n",
            "2400/2400 [==============================] - 6s 2ms/step - loss: 2.7492 - accuracy: 0.6289\n",
            "Epoch 2/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.4869 - accuracy: 0.8650\n",
            "Epoch 3/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.3650 - accuracy: 0.8950\n",
            "Epoch 4/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2976 - accuracy: 0.9147\n",
            "Epoch 5/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2593 - accuracy: 0.9275\n",
            "Epoch 6/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2469 - accuracy: 0.9303\n",
            "Epoch 7/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2204 - accuracy: 0.9388\n",
            "Epoch 8/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2117 - accuracy: 0.9415\n",
            "Epoch 9/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.1937 - accuracy: 0.9467\n",
            "Epoch 10/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.1936 - accuracy: 0.9479\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.1864 - accuracy: 0.9510\n",
            "Epoch 1/10\n",
            "2400/2400 [==============================] - 6s 2ms/step - loss: 3.1312 - accuracy: 0.5777\n",
            "Epoch 2/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.5352 - accuracy: 0.8553\n",
            "Epoch 3/10\n",
            "2400/2400 [==============================] - 6s 3ms/step - loss: 0.4115 - accuracy: 0.8875\n",
            "Epoch 4/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.3328 - accuracy: 0.9080\n",
            "Epoch 5/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2922 - accuracy: 0.9207\n",
            "Epoch 6/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2665 - accuracy: 0.9281\n",
            "Epoch 7/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2438 - accuracy: 0.9335\n",
            "Epoch 8/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2330 - accuracy: 0.9354\n",
            "Epoch 9/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2218 - accuracy: 0.9415\n",
            "Epoch 10/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2083 - accuracy: 0.9443\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2147 - accuracy: 0.9433\n",
            "Epoch 1/10\n",
            "2400/2400 [==============================] - 6s 2ms/step - loss: 2.7395 - accuracy: 0.6203\n",
            "Epoch 2/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.5280 - accuracy: 0.8582\n",
            "Epoch 3/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.4015 - accuracy: 0.8923\n",
            "Epoch 4/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.3586 - accuracy: 0.9028\n",
            "Epoch 5/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.3153 - accuracy: 0.9154\n",
            "Epoch 6/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2911 - accuracy: 0.9202\n",
            "Epoch 7/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2738 - accuracy: 0.9245\n",
            "Epoch 8/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2572 - accuracy: 0.9295\n",
            "Epoch 9/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2455 - accuracy: 0.9321\n",
            "Epoch 10/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2277 - accuracy: 0.9371\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.2067 - accuracy: 0.9473\n",
            "Epoch 1/10\n",
            "2400/2400 [==============================] - 6s 2ms/step - loss: 3.1836 - accuracy: 0.5202\n",
            "Epoch 2/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.5800 - accuracy: 0.8392\n",
            "Epoch 3/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.4348 - accuracy: 0.8847\n",
            "Epoch 4/10\n",
            "2400/2400 [==============================] - 6s 2ms/step - loss: 0.3601 - accuracy: 0.9024\n",
            "Epoch 5/10\n",
            "2400/2400 [==============================] - 6s 3ms/step - loss: 0.3131 - accuracy: 0.9140\n",
            "Epoch 6/10\n",
            "2400/2400 [==============================] - 6s 3ms/step - loss: 0.2673 - accuracy: 0.9258\n",
            "Epoch 7/10\n",
            "2400/2400 [==============================] - 6s 3ms/step - loss: 0.2546 - accuracy: 0.9322\n",
            "Epoch 8/10\n",
            "2400/2400 [==============================] - 6s 2ms/step - loss: 0.2337 - accuracy: 0.9349\n",
            "Epoch 9/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2247 - accuracy: 0.9388\n",
            "Epoch 10/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2068 - accuracy: 0.9430\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.1999 - accuracy: 0.9452\n",
            "Epoch 1/10\n",
            "2400/2400 [==============================] - 6s 2ms/step - loss: 3.4171 - accuracy: 0.5597\n",
            "Epoch 2/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.5539 - accuracy: 0.8530\n",
            "Epoch 3/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.4129 - accuracy: 0.8893\n",
            "Epoch 4/10\n",
            "2400/2400 [==============================] - 6s 2ms/step - loss: 0.3607 - accuracy: 0.8997\n",
            "Epoch 5/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.3173 - accuracy: 0.9130\n",
            "Epoch 6/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2800 - accuracy: 0.9237\n",
            "Epoch 7/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2715 - accuracy: 0.9261\n",
            "Epoch 8/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2480 - accuracy: 0.9334\n",
            "Epoch 9/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2405 - accuracy: 0.9347\n",
            "Epoch 10/10\n",
            "2400/2400 [==============================] - 5s 2ms/step - loss: 0.2316 - accuracy: 0.9376\n",
            "600/600 [==============================] - 1s 1ms/step - loss: 0.1979 - accuracy: 0.9509\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 28.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3000/3000 [==============================] - 7s 2ms/step - loss: 2.5574 - accuracy: 0.6416\n",
            "Epoch 2/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.4511 - accuracy: 0.8740\n",
            "Epoch 3/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.3622 - accuracy: 0.8981\n",
            "Epoch 4/10\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.3076 - accuracy: 0.9116\n",
            "Epoch 5/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.2742 - accuracy: 0.9210\n",
            "Epoch 6/10\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.2560 - accuracy: 0.9276\n",
            "Epoch 7/10\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.2498 - accuracy: 0.9278\n",
            "Epoch 8/10\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.2320 - accuracy: 0.9329\n",
            "Epoch 9/10\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.2231 - accuracy: 0.9355\n",
            "Epoch 10/10\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.2036 - accuracy: 0.9438\n",
            "CPU times: user 34min, sys: 3min 8s, total: 37min 8s\n",
            "Wall time: 29min 19s\n",
            "--- metrics ---\n",
            "score: 0.9475333213806152\n",
            "--- best parameters ---\n",
            "\tbatch_size: 20\n",
            "\tepochs: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm3dfUka2vxB",
        "outputId": "9383a1f1-5a89-4464-a833-194276ebcc4e"
      },
      "source": [
        "from tensorflow import keras \n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.activations import relu, sigmoid\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "seed = 7\n",
        "np.random.seed(seed) # random seed for reproducability\n",
        "### create the model ###\n",
        "model = Sequential() # initiate the model \n",
        "model.add(Dense(50, input_dim=784, activation='relu')), # input layer, set dimension\n",
        "model.add(Dropout(0.1)), # set the drop out \n",
        "model.add(Dense(100, activation='relu')), # hidden layer\n",
        "model.add(Dropout(0.1)), # set the drop out \n",
        "model.add(Dense(50, activation='relu')), # hidden layer\n",
        "model.add(Dense(10, activation='sigmoid')) # output layer \n",
        "model.compile( # compile the model \n",
        "              optimizer = 'adam', \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy']\n",
        "              )\n",
        "### show summary ### \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_68 (Dense)             (None, 50)                39250     \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_69 (Dense)             (None, 100)               5100      \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 49,910\n",
            "Trainable params: 49,910\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLIavG9J3nSH",
        "outputId": "044e0614-3282-4e7a-d43a-264b8acecb4d"
      },
      "source": [
        "print('--- model runtime ---')\n",
        "%time history = model.fit(X_train, y_train, batch_size=20, epochs=10, validation_split=.1, verbose=False) # fit the model \n",
        "scores = model.evaluate(X_test, y_test) # get the model score from evaluation\n",
        "print(f'model accuracy = {scores[1]*100}') # show the models accuracy score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- model runtime ---\n",
            "CPU times: user 1min 4s, sys: 5.58 s, total: 1min 10s\n",
            "Wall time: 47.5 s\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1736 - accuracy: 0.9550\n",
            "model accuracy = 95.49999833106995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "pb2G77ka6N2s",
        "outputId": "de614ff1-f406-4673-d0b9-0f84721a9e14"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "### plot the loss-MSE value ###\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbJGutZKhijy"
      },
      "source": [
        "##### RandomSearch CV "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "oBf5Ve-f6FZz",
        "outputId": "0cbc3565-aff1-4b7d-b994-5b3313b8f511"
      },
      "source": [
        "### parameter tuning options ###\n",
        "'''\n",
        "- tune 1-2 parameters at a time \n",
        "- add parameters to model function input\n",
        "- set the list of values for the parameter in the model \n",
        "- add the parameter to the param_grid dictionary\n",
        "'''\n",
        "# def create_model(optimizer='rmsprop', init='glorot_uniform',dropout_rate=0.0, weight_constraint=0, activation='relu', learn_rate=0.01, momentum=0, neurons=1)\n",
        "# optimizers = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "# init = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'] # network weight initializer, will change with choice of activation function \n",
        "# activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'], # controls the non-linearity of individual neurons and when to fire, 'sigmoid' last layer for 0-1 value outputs\n",
        "# epochs = [10, 50, 100] # no model input necessary, how many times the model will run \n",
        "# batch_size = [5, 10, 20] # no model input necessary, # of samples to run in each epoch\n",
        "# learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3] # combine with momentum, use SGD optimizer, how much to update the weight after each batch  \n",
        "# momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9] # combine with learn_rate, use SGD optimizer\n",
        "# optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
        "# weight_constraint = [1, 2, 3, 4, 5] # combine with dropout \n",
        "# dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] # combine with weight_constraint\n",
        "# neurons = [1, 5, 10, 15, 20, 25, 30]\n",
        "# param_grid = dict(batch_size=batch_size, epochs=epochs, batch_size=batch_size, learn_rate=learn_rate, momentum=momentum, weight_constraint=weight_constraint, dropout_rate=dropout_rate, neurons)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n- tune 1-2 parameters at a time \\n- add parameters to model function input\\n- set the list of values for the parameter in the model \\n- add the parameter to the param_grid dictionary\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzCl1nVxchYW",
        "outputId": "94e413bf-9edd-4481-e190-0c5d0dc40bb2"
      },
      "source": [
        "from tensorflow import keras \n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from keras.optimizers import Adam, Nadam, RMSprop\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.activations import relu, sigmoid\n",
        "from sklearn.model_selection import cross_val_score\n",
        "### create a model function ### \n",
        "def create_model(optimizers):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(50, input_dim=784, activation='relu')), # input layer \n",
        "    model.add(Dropout(0.1)), # set the drop out \n",
        "    model.add(Dense(100, activation='relu')), # hidden layer\n",
        "    model.add(Dropout(0.1)), # set the drop out \n",
        "    model.add(Dense(50, activation='relu')), # hidden layer\n",
        "    model.add(Dense(10, activation='sigmoid')) # output layer        \n",
        "    model.compile(\n",
        "                  optimizer = optimizers, # tuning \n",
        "                  loss = 'categorical_crossentropy', \n",
        "                  metrics = ['accuracy'] # for classification use accuracy\n",
        "                 )\n",
        "\n",
        "    return model\n",
        "\n",
        "seed = 7\n",
        "np.random.seed(seed) # random seed for reproducibility\n",
        "model1 = KerasClassifier(build_fn=create_model) # initiate the model\n",
        "### set parameters to tune ### \n",
        "optimizers = ['rmsprop', 'adam', 'Nadam'] # tune new parameter \n",
        "epochs = [10] # set the epoch \n",
        "batch_size = [20] # set the batch size\n",
        "param_grid = dict(optimizers = optimizers, batch_size = batch_size, epochs = epochs) # create the param dict\n",
        "random = RandomizedSearchCV(model1, param_distributions = param_grid, n_jobs=-1, verbose=1) # initiate the model \n",
        "print('--- model runtime ---')\n",
        "%time random.fit(X_train, y_train) # fit the data\n",
        "### model metrics ###\n",
        "print('--- metrics ---')\n",
        "print(\"score:\", (random.best_score_)) # show the score \n",
        "print('--- best parameters ---')\n",
        "for param, value in random.best_params_.items(): # show the best params\n",
        "    print('\\t{}: {}'.format(param, value))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- model runtime ---\n",
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 10.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0491 - accuracy: 0.6287\n",
            "Epoch 2/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.4446 - accuracy: 0.8787\n",
            "Epoch 3/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.3259 - accuracy: 0.9128\n",
            "Epoch 4/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.2692 - accuracy: 0.9264\n",
            "Epoch 5/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.2353 - accuracy: 0.9355\n",
            "Epoch 6/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.2091 - accuracy: 0.9420\n",
            "Epoch 7/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.2027 - accuracy: 0.9449\n",
            "Epoch 8/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.1890 - accuracy: 0.9476\n",
            "Epoch 9/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.1747 - accuracy: 0.9530\n",
            "Epoch 10/10\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.1659 - accuracy: 0.9551\n",
            "CPU times: user 1min 17s, sys: 7.38 s, total: 1min 24s\n",
            "Wall time: 11min 29s\n",
            "--- metrics ---\n",
            "score: 0.9483500123023987\n",
            "--- best parameters ---\n",
            "\toptimizers: adam\n",
            "\tepochs: 10\n",
            "\tbatch_size: 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkBtpmPu3BBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61e7d90-4f49-4fa6-e43b-5fac3e049298"
      },
      "source": [
        "from tensorflow import keras \n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.activations import relu, sigmoid\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "seed = 7\n",
        "np.random.seed(seed) # random seed for reproducibility\n",
        "### create the model ### \n",
        "model = Sequential() # initiate the model \n",
        "model.add(Dense(50, input_dim=784, activation='relu')), # input layer \n",
        "model.add(Dropout(0.1)), # set drop out \n",
        "model.add(Dense(100, activation='relu')), # hidden layer\n",
        "model.add(Dropout(0.1)), # set drop out \n",
        "model.add(Dense(50, activation='relu')), # hidden layer\n",
        "model.add(Dense(10, activation='sigmoid')) # output layer \n",
        "model.compile( # compile the model \n",
        "              optimizer = 'adam', \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy']\n",
        "              )\n",
        "### show summary ### \n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_84 (Dense)             (None, 50)                39250     \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_85 (Dense)             (None, 100)               5100      \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_86 (Dense)             (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_87 (Dense)             (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 49,910\n",
            "Trainable params: 49,910\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abntX5ei2i5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "965d81a7-7e95-4c50-8836-a893b3ee2d44"
      },
      "source": [
        "print('--- model runtime ---')\n",
        "%time history = model.fit(X_train, y_train, batch_size=20, epochs=10, validation_split=.1, verbose=False) # fit the model \n",
        "scores = model.evaluate(X_test, y_test) # get the model score from evaluation\n",
        "print(f'model accuracy = {scores[1]*100}') # show the models accuracy score "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- model runtime ---\n",
            "CPU times: user 1min 2s, sys: 5.62 s, total: 1min 7s\n",
            "Wall time: 45.3 s\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1824 - accuracy: 0.9544\n",
            "model accuracy = 95.44000029563904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKux3Dvg6Qld",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "d8f8b946-479c-4ca8-b3df-8618b9969ef2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "### plot the loss-MSE value ###\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}